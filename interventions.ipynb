{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from ast import literal_eval\n",
    "import yaml\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models import cb_gan\n",
    "from utils.datasets import ColoredMNIST, Libero\n",
    "from utils.utils import get_dataset\n",
    "\n",
    "dev = \"cuda:0\"\n",
    "device = torch.device(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Config\n",
    "config_file = 'config/cb_gan/libero_90.yaml'\n",
    "with open(config_file, 'r') as stream:\n",
    "\t\tconfig = yaml.safe_load(stream)\n",
    "\n",
    "if (torch.cuda.is_available()  and  config[\"train_config\"][\"use_cuda\"] ) :\n",
    "    use_cuda=True\n",
    "else:\n",
    "    use_cuda=False\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "\n",
    "config['dataset']['batch_size'] = 5\n",
    "config['dataset']['test_batch_size'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Data\n",
    "dataloader , test_loader = get_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cb_gan.cbGAN(config)\n",
    "model.load_state_dict(torch.load(\"models/cb_gan_libero_90_15.pt\"))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 22])\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get just one sample of data\n",
    "imgs, concepts = next(iter(test_loader))\n",
    "imgs = Variable(imgs.type(FloatTensor))\n",
    "imgs = imgs.to(device)\n",
    "# concepts = [c.to(device) for c in concepts]\n",
    "print(concepts.size())\n",
    "concept_list = [int(item) for item in concepts[0]]\n",
    "print(concept_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64])\n"
     ]
    }
   ],
   "source": [
    "# Process sample and retrieve probs and ground truth concepts\n",
    "_, _, latent = model.enc(imgs)\n",
    "print(latent.size())\n",
    "fake_data,logits,_,_= model.dec(latent, return_all=True)\n",
    "gen_imgs = model.dec(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = torch.tensor([float(l) for i, l in enumerate(logits[0]) if i % 2 == 0])\n",
    "neg = torch.tensor([float(l) for i, l in enumerate(logits[0]) if i % 2 == 1])\n",
    "mod_logits = []\n",
    "for p, n in zip(pos, neg):\n",
    "    sample = torch.cat([p.reshape(-1,1), n.reshape(-1,1)], axis=1).to(device)\n",
    "    sample = sample.unsqueeze(1).repeat(5, 1, 1)\n",
    "    mod_logits.append(sample.squeeze())\n",
    "    # if mod_logits == None:\n",
    "    #     mod_logits = sample\n",
    "    # else:\n",
    "    #     mod_logits = torch.cat((mod_logits, sample), 1)\n",
    "# mod_logits = torch.cat([pos.reshape(-1,1), neg.reshape(-1,1)], axis=1)\n",
    "mod_logits[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_logits[1][0][0] = 0\n",
    "mod_logits[1][0][1] = 1\n",
    "len(mod_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call code again with interventions on probs and observe how the output image is affected\n",
    "# fake_data_mod,logits_mod,_,_= model.dec(latent,probs=mod_logits, return_all=True)\n",
    "gen_imgs_latent = model.dec(latent,probs=mod_logits)\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# real_img = torch.swapaxes(imgs[0], 0, 2).cpu().detach().numpy()\n",
    "# fake_img = torch.swapaxes(fake_data[0], 0, 2).cpu().detach().numpy()\n",
    "# real_img = np.rot90(real_img)\n",
    "# fake_img = np.rot90(fake_img)\n",
    "# fake_img_mod = torch.swapaxes(fake_data_mod[0], 0, 2).cpu().detach().numpy()\n",
    "# fake_img_mod = np.rot90(fake_img_mod)\n",
    "\n",
    "# plt.imshow(real_img)\n",
    "# plt.show()\n",
    "# plt.imshow(fake_img)\n",
    "# plt.show()\n",
    "# plt.imshow(fake_img_mod)\n",
    "# plt.show()\n",
    "\n",
    "save_image(gen_imgs.data, \"intervention.png\", nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
